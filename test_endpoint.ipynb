{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "import torchaudio\n",
    "import sagemaker\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeech(\"test-clean\")\n",
    "audio, sample_rate, text, _, _, _ = dataset.dataset[0]\n",
    "\n",
    "# Convert the audio data to a Base64-encoded string\n",
    "audio_base64_encoded = base64.b64encode(audio.numpy().tobytes()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in JSON format\n",
    "data = {\n",
    "    \"audio_base64\": audio_base64_encoded,\n",
    "    \"sample_rate\": sample_rate,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "endpoint_name = 'whisper-gpu-endpoint'\n",
    "content_type = 'application/json'  # You may need to adjust this based on your use case\n",
    "\n",
    "# Convert the request data to JSON\n",
    "request_payload = json.dumps(data)\n",
    "\n",
    "# Send the request to the endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=request_payload\n",
    ")\n",
    "\n",
    "# Read and process the response\n",
    "response_body = response['Body'].read()\n",
    "\n",
    "# The response may be in JSON format, so you can parse it if needed\n",
    "response_data = json.loads(response_body)\n",
    "\n",
    "# Process the response_data as per your application's needs\n",
    "print(response_data)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
